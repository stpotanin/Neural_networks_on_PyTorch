{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPN/FP3SVirkx5FOGLq3VDZ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576200/step/5\n",
        "\n",
        "https://github.com/selfedu-rus/neuro-pytorch/blob/main/solves/4.3.3"
      ],
      "metadata": {
        "id": "Qa02x_yx2kor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrc2D4ED2eX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8957ade-28fa-4767-dd7b-95fe0ab95924"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Длина train: 990\n",
            "Длина test: 1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.018559271469712257"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from collections.abc import Sequence\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "# здесь объявляйте класс модели\n",
        "\n",
        "x = torch.linspace(-20, 20, 2000)\n",
        "y = torch.cos(x) + 0.5 * torch.sin(5*x) + 0.1 * torch.randn_like(x)\n",
        "\n",
        "# Вспомогательные переменные:\n",
        "total = len(x)      # общее количество отсчетов\n",
        "train_size = 1000   # размер обучающей выборки\n",
        "seq_length = 10     # число предыдущих отсчетов, по которым строится прогноз следующего значения\n",
        "\n",
        "# Наборы данных для обучения и тестирования:\n",
        "y.unsqueeze_(1) # (2000) -> (2000, 1)\n",
        "'''\n",
        " torch.cat для объединения срезов y. Каждый срез — это 10 последовательных элементов (i до i+seq_length),\n",
        " и такие срезы берутся для i от 0 до train_size - seq_length - 1.\n",
        " Получается тензор с размерностями (seq_length, количество примеров).\n",
        "'''\n",
        "train_data_y = torch.cat([y[i:i+seq_length] for i in range(train_size-seq_length)], dim=1)\n",
        "train_targets = torch.tensor([y[i+seq_length].item() for i in range(train_size-seq_length)])\n",
        "print('Длина train:', len(train_targets))\n",
        "\n",
        "test_data_y = torch.cat([y[i:i+seq_length] for i in range(train_size-seq_length, total-seq_length)], dim=1)\n",
        "test_targets = torch.tensor([y[i+seq_length].item() for i in range(train_size-seq_length, total-seq_length)])\n",
        "print('Длина test:', len(test_targets))\n",
        "'''\n",
        "permute меняет местами оси, чтобы примеры были первым измерением, как требуется в DataLoader\n",
        "(seq_length, количество примеров) -> (количество примеров, seq_length):\n",
        "'''\n",
        "d_train = data.TensorDataset(train_data_y.permute(1, 0), train_targets)\n",
        "d_test = data.TensorDataset(test_data_y.permute(1, 0), test_targets)\n",
        "\n",
        "# Объекты датасетов и DataLoader:\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "test_data = data.DataLoader(d_test, batch_size=len(d_test), shuffle=False)\n",
        "\n",
        "class RNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(input_size=1, hidden_size=5, batch_first=True)\n",
        "        self.fc = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h = self.rnn(x)\n",
        "        # print(h.shape) # h.shape: (num_layers, batch_size, hidden_size) = [1, 8, 5]\n",
        "        # output = self.fc(h) # плохой вариант, хоть и рабочий\n",
        "        output = self.fc(h.squeeze(0)) # правильный вариант\n",
        "        return output\n",
        "\n",
        "# создание объекта модели\n",
        "model = RNNModel()\n",
        "\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=0.001) # оптимизатор RMSprop с шагом обучения 0.001\n",
        "loss_func = nn.MSELoss() # функция потерь - средний квадрат ошибок\n",
        "\n",
        "epochs = 5   # число эпох\n",
        "model.train() # переведите модель в режим обучения\n",
        "\n",
        "for _e in range(epochs):\n",
        "    for x_train, y_train in train_data:\n",
        "        # добавляем размерность для подачи в модель, убираем лишнюю для метрики\n",
        "        predict = model(x_train.unsqueeze(-1)).squeeze()\n",
        "        loss = loss_func(predict, y_train)\n",
        "\n",
        "        # выполните один шаг обучения (градиентного спуска)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# переведите модель в режим эксплуатации\n",
        "model.eval()\n",
        "d, t = next(iter(test_data))\n",
        "\n",
        "# с использованием менеджера torch.no_grad вычислите прогнозы для выборки d\n",
        "with torch.no_grad():\n",
        "    # добавляем размерность для подачи в модель, убираем лишнюю для метрики\n",
        "    predict = model(d.unsqueeze(-1)).squeeze()\n",
        "\n",
        "# вычислите потери с помощью loss_func для predict и t; значение Q сохраните в виде вещественного числа\n",
        "Q = loss_func(predict, t).item()\n",
        "\n",
        "Q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN слой возвращает вектор h размерностью (num_layers, batch_size, hidden_size). В нашем случае [1, 8, 5].\n",
        "И линейный слой принимает такую форму без модифацикаций. Полагаю, что PyTorch делает[1*8, 5] = [8,5] и всё работает.\n",
        "Но при num_layers > 1 такой финт уже не пройдёт, поэтому лучше сделать выход RNN явным, дабавив .squeeze(0)"
      ],
      "metadata": {
        "id": "gN0z1e81Oi5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Исправленный код (пересечение train и test)\n",
        "# Тестовая выборка (исправлено!)\n",
        "test_data_y = torch.cat([\n",
        "    y[i:i+seq_length]\n",
        "    for i in range(train_size, total-seq_length)  # ← ключевое исправление!\n",
        "], dim=1)\n",
        "\n",
        "test_targets = torch.tensor([\n",
        "    y[i+seq_length].item()\n",
        "    for i in range(train_size, total-seq_length)\n",
        "])"
      ],
      "metadata": {
        "id": "eswZ3c3TjaJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Решение https://github.com/selfedu-rus/neuro-pytorch/blob/main/solves/4.3.3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "# здесь объявляйте класс модели\n",
        "class MyModelRNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self._h_size = 5\n",
        "        self.rnn = nn.RNN(1, self._h_size, batch_first=True)\n",
        "        self.output = nn.Linear(self._h_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, h = self.rnn(x)\n",
        "        return self.output(h)\n",
        "\n",
        "\n",
        "x = torch.linspace(-20, 20, 2000)\n",
        "y = torch.cos(x) + 0.5 * torch.sin(5*x) + 0.1 * torch.randn_like(x)\n",
        "\n",
        "total = len(x)      # общее количество отсчетов\n",
        "train_size = 1000   # размер обучающей выборки\n",
        "seq_length = 10     # число предыдущих отсчетов, по которым строится прогноз следующего значения\n",
        "\n",
        "y.unsqueeze_(1)\n",
        "train_data_y = torch.cat([y[i:i+seq_length] for i in range(train_size-seq_length)], dim=1)\n",
        "train_targets = torch.tensor([y[i+seq_length].item() for i in range(train_size-seq_length)])\n",
        "\n",
        "test_data_y = torch.cat([y[i:i+seq_length] for i in range(train_size-seq_length, total-seq_length)], dim=1)\n",
        "test_targets = torch.tensor([y[i+seq_length].item() for i in range(train_size-seq_length, total-seq_length)])\n",
        "\n",
        "d_train = data.TensorDataset(train_data_y.permute(1, 0), train_targets)\n",
        "d_test = data.TensorDataset(test_data_y.permute(1, 0), test_targets)\n",
        "\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "test_data = data.DataLoader(d_test, batch_size=len(d_test), shuffle=False)\n",
        "\n",
        "model = MyModelRNN() # создание объекта модели\n",
        "\n",
        "optimizer = optim.RMSprop(params=model.parameters(), lr=0.001)\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "epochs = 5 # число эпох\n",
        "model.train()\n",
        "\n",
        "for _e in range(epochs):\n",
        "    for x_train, y_train in train_data:\n",
        "        predict = model(x_train.unsqueeze(-1)).squeeze()\n",
        "        loss = loss_func(predict, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "d, t = next(iter(test_data))\n",
        "with torch.no_grad():\n",
        "    predict = model(d.unsqueeze(-1)).squeeze()\n",
        "\n",
        "Q = loss_func(predict, t).item()\n",
        "\n",
        "Q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbxfeJRa6pDC",
        "outputId": "5a7eb2dc-0a75-4fa5-b3d3-ec165ca2aa5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02265542931854725"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}