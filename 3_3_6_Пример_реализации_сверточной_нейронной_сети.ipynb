{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjnFVm3tocu3ef5jF11TF1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576188/step/6"
      ],
      "metadata": {
        "id": "JJvLbsRf7b_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Расчёт размера изображения после применения слоёв Conv2d и MaxPool2d\n",
        "\n",
        "H_in, W_in = 32, 32 # высота и ширина входного изображения\n",
        "\n",
        "# 1-й слой (Conv2d)\n",
        "p = (2, 2)          # padding, количество пикселей, добавленных к границам изображения\n",
        "k = (5, 5)          # kernel_size, размер ядра свертки\n",
        "s = (1, 1)          # stride, шаг с которым ядро перемещается по изображению\n",
        "d = (1, 1)          # dilation, расстояние между элементами ядра (когда не все пиксели учитываем)\n",
        "\n",
        "H_1 = (H_in + 2 * p[0] - d[0] * (k[0] - 1) - 1) / s[0] + 1\n",
        "W_1 = (H_in + 2 * p[1] - d[1] * (k[1] - 1) - 1) / s[1] + 1\n",
        "\n",
        "# 2-й слой (MaxPool2d)\n",
        "H_2 = H_1 // 2\n",
        "W_2 = W_1 // 2\n",
        "\n",
        "# 3-й слой (Conv2d)\n",
        "p = (1, 1)\n",
        "k = (3, 3)\n",
        "s = (1, 1)\n",
        "d = (1, 1)\n",
        "\n",
        "H_3 = (H_2 + 2 * p[0] - d[0] * (k[0] - 1) - 1) / s[0] + 1\n",
        "W_3 = (W_2 + 2 * p[1] - d[1] * (k[1] - 1) - 1) / s[1] + 1\n",
        "\n",
        "# 4-й слой (MaxPool2d)\n",
        "H_4 = H_3 // 2\n",
        "W_4 = W_3 // 2\n",
        "\n",
        "print(H_4, W_4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUia9bzw8DoD",
        "outputId": "3f59ee24-b747-4490-a12a-bccbfd418f0b",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.0 8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB77k83M7Joj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "631c8784-469b-444e-e999-c8d8a7a392cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.ImageNormalize at 0x7fa06613fb90>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ImageNormalize():\n",
        "    def __call__(self, tensor: torch.Tensor) -> torch.Tensor:\n",
        "        min_t = tensor.min()\n",
        "        max_t = tensor.max()\n",
        "        return (tensor - min_t) / (max_t - min_t)\n",
        "\n",
        "# генерация образов выборки\n",
        "total = 100     # размер выборки\n",
        "H, W = 32, 32   # размер изображений\n",
        "circle = torch.tensor([[0, 0, 0, 255, 255, 255, 255, 0, 0, 0],\n",
        "                       [0, 255, 255, 255, 255, 255, 255, 255, 255, 0],\n",
        "                       [0, 255, 255, 255, 255, 255, 255, 255, 255, 0],\n",
        "                       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
        "                       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
        "                       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
        "                       [255, 255, 255, 255, 255, 255, 255, 255, 255, 255],\n",
        "                       [0, 255, 255, 255, 255, 255, 255, 255, 255, 0],\n",
        "                       [0, 255, 255, 255, 255, 255, 255, 255, 255, 0],\n",
        "                       [0, 0, 0, 255, 255, 255, 255, 0, 0, 0]], dtype=torch.float32)\n",
        "Hc, Wc = circle.size()\n",
        "\n",
        "\n",
        "def _generate_img(_H, _W, _Hc, _Wc, _x, _y, _circle, _tr): # вспомогательная функция\n",
        "    img = torch.rand(_H, _W) * 20\n",
        "    img[_x:_x+_Hc, _y:_y+Wc] = _circle\n",
        "    return _tr(img.view(1, 1, _H, _W))\n",
        "\n",
        "\n",
        "# Функция для создания объекта нормализатора с применением (через call)\n",
        "transform = ImageNormalize()\n",
        "\n",
        "data_y = torch.tensor([(torch.randint(0, H-Hc, (1, )), torch.randint(0, W-Wc, (1, ))) for _ in range(total)])\n",
        "data_x = torch.cat([_generate_img(H, W, Hc, Wc, _x[0], _x[1], circle, transform) for _x in data_y], dim=0)\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, (5, 5), stride=1, padding=2, bias=True),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d((2, 2), stride=2),\n",
        "    nn.Conv2d(16, 32, (3, 3), stride=1, padding=1, bias=True),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.MaxPool2d((2, 2), stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(32 * 8 * 8, 2, bias=True)  # 2 класса\n",
        ")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "predict = model(data_x)\n",
        "\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "Q = loss_func(predict, data_y.type(torch.float32)).item()\n",
        "\n",
        "# print(Q)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Расчёт размера изображения после применения слоя torch.nn.Conv2d\n",
        "H_in, W_in = 8, 8   # высота и ширина входного изображения\n",
        "p = (1, 1)          # padding, количество пикселей, добавленных к границам изображения\n",
        "k = (3, 3)          # kernel_size, размер ядра свертки\n",
        "s = (1, 1)          # stride, шаг с которым ядро перемещается по изображению\n",
        "d = (1, 1)          # dilation, расстояние между элементами ядра (когда не все пиксели учитываем)\n",
        "\n",
        "H_out = (H_in + 2 * p[0] - d[0] * (k[0] - 1) - 1) / s[0] + 1\n",
        "W_out = (H_in + 2 * p[1] - d[1] * (k[1] - 1) - 1) / s[1] + 1\n",
        "\n",
        "H_out, W_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_TwG9iAXuX0",
        "outputId": "f2260531-f870-4cb8-c87b-dac0256a692a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.0, 8.0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Размер изображения после применения слоя `torch.nn.Conv2d` можно рассчитать по следующей формуле:\n",
        "\n",
        "$$\n",
        "H_{\\text{out}} = \\left\\lfloor \\frac{H_{\\text{in}} + 2 \\times padding[0] - dilation[0] \\times (kernel\\_size[0] - 1) - 1}{stride[0]} + 1 \\right\\rfloor\n",
        "$$\n",
        "\n",
        "$$\n",
        "W_{\\text{out}} = \\left\\lfloor \\frac{W_{\\text{in}} + 2 \\times padding[1] - dilation[1] \\times (kernel\\_size[1] - 1) - 1}{stride[1]} + 1 \\right\\rfloor\n",
        "$$\n",
        "\n",
        "Где:\n",
        "\n",
        "- $H_{\\text{in}}$$ и $$W_{\\text{in}}$ — высота и ширина входного изображения[4].\n",
        "- $\\text{padding}$ — количество пикселей, добавленных к границам изображения[1][4].\n",
        "- $\\text{kernel_size}$ — размер ядра свертки[1][4].\n",
        "- $\\text{stride}$ — шаг, с которым ядро перемещается по изображению[1][4].\n",
        "- $\\text{dilation}$ — расстояние между элементами ядра[4].\n",
        "\n",
        "**Пример:**\n",
        "Если входное изображение имеет размер $28 \\times 28$, а параметры слоя заданы как `Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=0)`, то размер выходного изображения будет:\n",
        "\n",
        "$$\n",
        "H_{\\text{out}} = \\left\\lfloor \\frac{28 + 2 \\times 0 - 1 \\times (5 - 1) - 1}{1} + 1 \\right\\rfloor = 24\n",
        "$$\n",
        "\n",
        "$$\n",
        "W_{\\text{out}} = \\left\\lfloor \\frac{28 + 2 \\times 0 - 1 \\times (5 - 1) - 1}{1} + 1 \\right\\rfloor = 24\n",
        "$$\n",
        "\n",
        "Таким образом, выходное изображение будет иметь размер $24 \\times 24$[2][4].\n",
        "\n",
        "Citations:\n",
        "[1] https://proproprogs.ru/nn_pytorch/pytorch-klassy-conv2d-i-maxpool2d\n",
        "\n",
        "[2] https://discuss.pytorch.org/t/pytorch-nn-conv2d-computation-of-number-of-features-output-from-nn-conv2d/150750\n",
        "\n",
        "[3] https://www.bizkit.ru/2020/02/25/17169/\n",
        "\n",
        "[4] https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
        "\n",
        "\n",
        "[5] https://ru.stackoverflow.com/questions/1170799/k%D0%B0%D0%BA-%D0%BF%D0%BE%D0%BC%D0%B5%D0%BD%D1%8F%D0%B5%D1%82%D1%81%D1%8F-%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80-%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F-%D0%BF%D0%BE-%D1%81%D0%B2%D1%91%D1%80%D1%82%D0%BE%D1%87%D0%BD%D0%BE%D0%B9-%D1%81%D0%B5%D1%82%D0%B8\n",
        "\n",
        "[6] https://stepik.org/lesson/309343/step/5\n",
        "\n",
        "[7] https://habr.com/ru/articles/456740/\n",
        "\n",
        "[8] https://stackoverflow.com/questions/56675943/meaning-of-parameters-in-torch-nn-conv2d\n",
        "\n",
        "[9] https://robocraft.ru/computervision/427\n",
        "\n",
        "[10] https://habr.com/ru/articles/454986/\n",
        "\n",
        "---\n",
        "Answer from Perplexity: pplx.ai/share"
      ],
      "metadata": {
        "id": "SymOIFgOiJo7"
      }
    }
  ]
}