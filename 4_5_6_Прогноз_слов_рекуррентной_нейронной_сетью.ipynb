{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFM4RVFQMfS+BySDpVcD7z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576202/step/6"
      ],
      "metadata": {
        "id": "TVSIJwX6xwig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–æ–¥—É–ª—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –¥–ª—è —Ç–µ—Å—Ç–∞\n",
        "!pip install navec\n",
        "from navec import Navec\n",
        "import requests\n",
        "\n",
        "url_navec_hudlit = 'https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
        "\n",
        "response = requests.get(url_navec_hudlit, stream=True)\n",
        "with open('navec_hudlit_v1_12B_500K_300d_100q.tar', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
        "global_navec = Navec.load(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQkiBx98u8UT",
        "outputId": "8a96b451-d7b0-4a44-fd0f-d27191fefd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting navec\n",
            "  Downloading navec-0.10.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from navec) (2.0.2)\n",
            "Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: navec\n",
            "Successfully installed navec-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
        "is_word = '–∫–∞–∂–¥—ã–π' in global_navec  # –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
        "v = global_navec['–∫–∞–∂–¥—ã–π']          # embedding —Å–ª–æ–≤–∞ '–∫–∞–∂–¥—ã–π'\n",
        "indx = global_navec.vocab['–∫–∞–∂–¥—ã–π'] # –∏–Ω–¥–µ–∫—Å —Å–ª–æ–≤–∞ '–∫–∞–∂–¥—ã–π' –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
        "\n",
        "is_word, v[:3], indx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ4idycLDn6C",
        "outputId": "9c5d7d61-b381-455c-ee39-a097cba0a86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, array([ 0.05372348, -0.0813841 , -0.51375115], dtype=float32), 161025)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–≤–≤–∞–Ω–∏—è\n",
        "_global_var_text = [\n",
        "\"–ö–∞–∫ —è –æ—Ç–º–µ—á–∞–ª –≤–æ –≤–≤–µ–¥–µ–Ω–∏–∏ –ø—Ä–æ—Å—Ç–µ–π—à–∞—è –ù–° –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π\",\n",
        "\"–≠—Ç–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –ø—Ä–∏–º–µ—Ä –Ω–µ–π—Ä–æ —Å–µ—Ç–∏\",\n",
        "\"–ö–∞–∂–¥–∞—è —Å–≤—è–∑—å –º–µ–∂–¥—É –Ω–µ–π—Ä–æ–Ω–∞–º–∏ –∏–º–µ–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π\"\n",
        "]"
      ],
      "metadata": {
        "id": "_qwTe7eNvjXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ma5vPC83xres",
        "outputId": "e1c548ec-03ef-4147-b1e8-db1580bc7491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.0204, -0.4305, -0.3130,  ..., -0.5250,  0.1350,  0.2226],\n",
            "        [-0.4001,  0.3622, -0.3973,  ..., -0.0571,  0.1050,  0.3030],\n",
            "        [-0.0319,  0.4600,  0.1253,  ...,  0.5209,  0.2278, -0.2517],\n",
            "        [ 0.5255,  0.2983,  0.3089,  ..., -0.2217,  0.1690, -0.0966]]), tensor(332056))\n",
            "(tensor([[-0.4001,  0.3622, -0.3973,  ..., -0.0571,  0.1050,  0.3030],\n",
            "        [-0.0319,  0.4600,  0.1253,  ...,  0.5209,  0.2278, -0.2517],\n",
            "        [ 0.5255,  0.2983,  0.3089,  ..., -0.2217,  0.1690, -0.0966],\n",
            "        [-0.0460,  0.0078,  0.3391,  ...,  0.0788,  0.3901,  0.4029]]), tensor(407059))\n",
            "8\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "class WordsDataset(data.Dataset):\n",
        "    def __init__(self, prev_words=4):\n",
        "        super().__init__()\n",
        "        self.text = _global_var_text\n",
        "        df = []\n",
        "        for string in self.text:\n",
        "            s = [word for word in string.lower().split()]\n",
        "            for i in range(prev_words, len(s)):\n",
        "                df.append(s[i-prev_words:i+1])\n",
        "        self.df = df\n",
        "        self.length = len(self.df)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, indx):\n",
        "            prev_words = self.df[indx][:-1]\n",
        "            prev_words_emb = torch.stack([torch.as_tensor(global_navec[word]) for word in prev_words])\n",
        "            next_word = self.df[indx][-1]\n",
        "            next_word_indx = global_navec.vocab[next_word]\n",
        "\n",
        "            return prev_words_emb, torch.tensor(next_word_indx)\n",
        "\n",
        "d_train = WordsDataset(prev_words=4)\n",
        "\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
        "print(d_train[3])\n",
        "print(d_train[4])\n",
        "print(len(d_train))\n",
        "# [['–∫–∞–∫', '—è', '–æ—Ç–º–µ—á–∞–ª', '–≤–æ', '–≤–≤–µ–¥–µ–Ω–∏–∏'],\n",
        "#  ['—è', '–æ—Ç–º–µ—á–∞–ª', '–≤–æ', '–≤–≤–µ–¥–µ–Ω–∏–∏', '–ø—Ä–æ—Å—Ç–µ–π—à–∞—è'],\n",
        "#  ['–æ—Ç–º–µ—á–∞–ª', '–≤–æ', '–≤–≤–µ–¥–µ–Ω–∏–∏', '–ø—Ä–æ—Å—Ç–µ–π—à–∞—è', '–Ω—Å'],\n",
        "#  ['–≤–æ', '–≤–≤–µ–¥–µ–Ω–∏–∏', '–ø—Ä–æ—Å—Ç–µ–π—à–∞—è', '–Ω—Å', '–ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç'],\n",
        "#  ['–≤–≤–µ–¥–µ–Ω–∏–∏', '–ø—Ä–æ—Å—Ç–µ–π—à–∞—è', '–Ω—Å', '–ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç', '—Å–æ–±–æ–π'],\n",
        "#  ['—ç—Ç–æ', '–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π', '–ø—Ä–∏–º–µ—Ä', '–Ω–µ–π—Ä–æ', '—Å–µ—Ç–∏'],\n",
        "#  ['–∫–∞–∂–¥–∞—è', '—Å–≤—è–∑—å', '–º–µ–∂–¥—É', '–Ω–µ–π—Ä–æ–Ω–∞–º–∏', '–∏–º–µ–µ—Ç'],\n",
        "#  ['—Å–≤—è–∑—å', '–º–µ–∂–¥—É', '–Ω–µ–π—Ä–æ–Ω–∞–º–∏', '–∏–º–µ–µ—Ç', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title –≠—Ç–∞–ª–æ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "class WordsDataset(data.Dataset):\n",
        "    def __init__(self, navec_emb, prev_words=4):\n",
        "        self.prev_words = prev_words\n",
        "        self.navec_emb = navec_emb\n",
        "\n",
        "        self.lines = _global_var_text\n",
        "        self.vocab = set((\" \".join(self.lines)).lower().split())\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "        data = []\n",
        "        targets = []\n",
        "\n",
        "        for t in self.lines:\n",
        "            words = t.lower().split()\n",
        "            for item in range(len(words)-self.prev_words):\n",
        "                data.append([self.navec_emb[words[x]].tolist() for x in range(item, item + self.prev_words)])\n",
        "                targets.append(self.navec_emb.vocab[words[item+self.prev_words]])\n",
        "\n",
        "        self.data = torch.tensor(data)\n",
        "        self.targets = torch.tensor(targets)\n",
        "\n",
        "        self.length = len(data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.data[item], self.targets[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "d_train = WordsDataset(global_navec)\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
        "print(d_train[3])\n",
        "print(d_train[4])\n",
        "print(len(d_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGQK6FscZg8F",
        "outputId": "12f424cb-d0ee-4235-a423-eca292e653a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.0204, -0.4305, -0.3130,  ..., -0.5250,  0.1350,  0.2226],\n",
            "        [-0.4001,  0.3622, -0.3973,  ..., -0.0571,  0.1050,  0.3030],\n",
            "        [-0.0319,  0.4600,  0.1253,  ...,  0.5209,  0.2278, -0.2517],\n",
            "        [ 0.5255,  0.2983,  0.3089,  ..., -0.2217,  0.1690, -0.0966]]), tensor(332056))\n",
            "(tensor([[-0.4001,  0.3622, -0.3973,  ..., -0.0571,  0.1050,  0.3030],\n",
            "        [-0.0319,  0.4600,  0.1253,  ...,  0.5209,  0.2278, -0.2517],\n",
            "        [ 0.5255,  0.2983,  0.3089,  ..., -0.2217,  0.1690, -0.0966],\n",
            "        [-0.0460,  0.0078,  0.3391,  ...,  0.0788,  0.3901,  0.4029]]), tensor(407059))\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stepik.org/lesson/1576202/step/6?discussion=11320238&thread=solutions&unit=1597477\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "class WordsDataset(data.Dataset):\n",
        "    def __init__(self, navec_emb, prev_words):\n",
        "        self.prev_words = prev_words\n",
        "        self.navec_emb = navec_emb\n",
        "        self.text = _global_var_text\n",
        "        self.text = \" \".join(self.text)\n",
        "        self.text = self.text.replace('\\n', ' ')\n",
        "        self.text = re.sub(r'[^–ê-—èA-z- ]', '', self.text)\n",
        "        self.words = self.text.lower().split()\n",
        "        self.words = [word for word in self.words if word in self.navec_emb]\n",
        "        vocab = set(self.words)\n",
        "\n",
        "        self.int_to_word = dict(enumerate((vocab)))\n",
        "        self.word_to_int = {b: a for a, b in self.int_to_word.items()}\n",
        "        self.vocab_size = len(vocab)\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        _data = torch.stack([torch.tensor(self.navec_emb[self.words[x]])\n",
        "                              for x in range(item, item+self.prev_words)])\n",
        "        word = self.words[item + self.prev_words]\n",
        "        index = self.navec_emb.vocab[word]\n",
        "\n",
        "        return _data, torch.tensor(index)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words) - self.prev_words\n",
        "\n",
        "\n",
        "\n",
        "d_train = WordsDataset(global_navec, prev_words=4)\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä–∫–∞\n",
        "print(d_train[3])\n",
        "print(d_train[4])\n",
        "print(len(d_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbJI5GZNHS6M",
        "outputId": "fd6d33e7-724d-4bf0-a365-db91dd3e1ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[-0.0204, -0.4305, -0.3130,  ..., -0.5250,  0.1350,  0.2226],\n",
            "        [-0.4001,  0.3622, -0.3973,  ..., -0.0571,  0.1050,  0.3030],\n",
            "        [-0.0319,  0.4600,  0.1253,  ...,  0.5209,  0.2278, -0.2517],\n",
            "        [ 0.5255,  0.2983,  0.3089,  ..., -0.2217,  0.1690, -0.0966]]), tensor(332056))\n",
            "(tensor([[-0.4001,  0.3622, -0.3973,  ..., -0.0571,  0.1050,  0.3030],\n",
            "        [-0.0319,  0.4600,  0.1253,  ...,  0.5209,  0.2278, -0.2517],\n",
            "        [ 0.5255,  0.2983,  0.3089,  ..., -0.2217,  0.1690, -0.0966],\n",
            "        [-0.0460,  0.0078,  0.3391,  ...,  0.0788,  0.3901,  0.4029]]), tensor(407059))\n",
            "16\n"
          ]
        }
      ]
    }
  ]
}