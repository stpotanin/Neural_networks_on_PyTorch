{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQTerO1icrvThpKBAugIm0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576205/step/8"
      ],
      "metadata": {
        "id": "s20R_2RUFTk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Глобальные переменные\n",
        "_global_words_0 = ['аа', 'аатаа', 'аба', 'абба', 'абиба', 'ава', 'аваава', 'авава', 'авва', 'ага', 'агга', 'ада', 'адда', 'ажа', 'ака', 'акака', 'аканака', 'акика', 'акка', 'ала', 'алала', 'алафала', 'амакама', 'амма', 'ана', 'анапана', 'анасана', 'анатана', 'анисина', 'анна', 'анона', 'апа', 'апипа', 'аппа', 'ара', 'арара', 'арора', 'арра', 'арура', 'аса', 'ата', 'атета', 'атта', 'аулуа', 'афа', 'аха', 'ахаха', 'ахоха', 'ахха', 'аца', 'ацыца', 'ача', 'аша', 'баб', 'бараб', 'батаб', 'бахаб', 'биб', 'боб', 'вёв', 'вив', 'вызыв', 'гачаг', 'гег', 'гиг', 'гириг', 'гог', 'гыг', 'гэг', 'дед', 'дид', 'диороид', 'довод', 'дойод', 'дород', 'доход', 'дуд', 'еае', 'ейе', 'ёре', 'ере', 'ёте', 'жож', 'заказ', 'замаз', 'заз', 'зуз', 'чи', 'и', 'иааи', 'иаи', 'иби', 'иви', 'идииди', 'ижжи', 'изи', 'ики', 'или', 'илли', 'иньни', 'ири', 'ирори', 'ихи', 'ичи', 'ичиичи', 'ишши', 'йай', 'йой', 'каак', 'кабак', 'кавак', 'казак', 'кайак', 'как', 'канак', 'капак', 'карак', 'касак', 'кассак', 'кек', 'кёк', 'келек', 'келлек', 'керек', 'кесек', 'кечёк', 'кибик', 'кижик', 'кизик', 'киик', 'кийик', 'кик', 'килик', 'киллилиллик', 'киник', 'киноник', 'кичик', 'кишик', 'ковок', 'кок', 'коллок', 'колок', 'комок', 'конок', 'копок', 'коппок', 'корок', 'косок', 'кошок', 'кудук', 'кук', 'кумук', 'курук', 'куук', 'кыйык', 'кык', 'кытык', 'кэк', 'кюк', 'лаал', 'лал', 'лобол', 'лол', 'лыл', 'мадам', 'мазам', 'макам', 'мам', 'манам', 'марам', 'мелем', 'мем', 'мивим', 'мидим', 'миллим', 'мим', 'миним', 'мом', 'моном', 'мум', 'мурум', 'мэм', 'наан', 'набан', 'наган', 'назан', 'накан', 'нан', 'напан', 'насан', 'нашан', 'некен', 'нен', 'ненен', 'нигин', 'нимин', 'нойон', 'нон', 'ноон', 'норурон', 'нэн', 'нян', 'о', 'обибо', 'обо', 'ово', 'оддо', 'ойо', 'око', 'оло', 'ололо', 'оно', 'оо', 'оро', 'ороборо', 'оруро', 'оссо', 'офо', 'очо', 'ошо', 'переп', 'покоп', 'поп', 'посоп', 'потоп', 'пуп', 'радар', 'расар', 'ревер', 'реер', 'рейер', 'ремер', 'репер', 'реппер', 'рер', 'рогор', 'ророр', 'ротатор', 'ротор', 'рэпєр', 'рэппєр', 'сас', 'секес', 'сиис', 'солос', 'соссос', 'статс', 'суккус', 'сукус', 'сус', 'таат', 'такат', 'таннат', 'тартрат', 'тассат', 'тат', 'тауат', 'тидит', 'тиллит', 'тимит', 'тирит', 'тит', 'тихит', 'тозот', 'топот', 'торот', 'тумут', 'тут', 'тыыт', 'у', 'убу', 'уду', 'улу', 'уруушу', 'фараф', 'феф', 'ханнах', 'хенех', 'хох', 'целец', 'чаач', 'чабач', 'чавач', 'чагач', 'чепеч', 'чеч', 'чижич', 'шабаш', 'шалаш', 'шамаш', 'шараш', 'шереш', 'шириш', 'шиш', 'шош', 'шугуш', 'шумуш', 'щэщ', 'эвэ', 'эдэ']\n",
        "_global_words_1 = ['сарпиночник', 'контрабандист', 'мопед', 'вульгарность', 'ятрышник', 'следопыт', 'оперирование', 'шпажист', 'англосаксонец', 'натуралистичность', 'серница', 'раздел', 'памятник', 'антрополог', 'новорождённая', 'окрол', 'гальваноскоп', 'кофта', 'председатель', 'ржанище', 'помилованная', 'примирение', 'суберин', 'папуаска', 'злободневность', 'эпископ', 'неучтивость', 'адат', 'подавание', 'походка', 'хорь', 'брейд-вымпел', 'предпочтение', 'слепушонок', 'кудель', 'эдикт', 'разнеженность', 'духанщик', 'вертолётчица', 'светотехника', 'провозгласитель', 'бериллий', 'пискунья', 'отгонщик', 'глиптодонт', 'локомобиль', 'пресмыкание', 'старобытность', 'двупланность', 'лютеций', 'прирез', 'рявкание', 'перегрузка', 'токсиколог', 'искусительница', 'дикция', 'древность', 'сертификация', 'магистраль', 'фагоцитоз', 'всесторонность', 'армада', 'люэс', 'бутоньерка', 'полустишие', 'сельхозинвентарь', 'огранка', 'минускул', 'монотипист', 'дань', 'бармен', 'выпирание', 'противосияние', 'альтист', 'бекас', 'глиптотека', 'полиграфия', 'уменьшение', 'лункование', 'клирос', 'пагода', 'элементарность', 'предпочтительность', 'горицвет', 'ксилофон', 'игиль', 'паратость', 'ножовщик', 'гель', 'непроизносимость', 'отшвыривание', 'новолуние', 'обрезок', 'технеций', 'самбист', 'инсулин', 'бирманка', 'гвардия', 'папуас', 'оживание', 'заскабливание', 'переливт', 'кройка', 'контроверза', 'ниспровержение', 'нагреватель', 'плата', 'паралитик', 'платан', 'эндокард', 'скликание', 'инвенция', 'раскутывание', 'загустение', 'чека', 'перенагревание', 'припыл', 'тенётчик', 'натюрморист', 'цивилизованность', 'упрощение', 'отопленец', 'свечка', 'предплужник', 'юродивая', 'неприличность', 'вех', 'лежание', 'драчливость', 'фидеист', 'дезодорант', 'прокапчивание', 'сбережение', 'посыльная', 'фольклористика', 'вдохновитель', 'культурница', 'виноградарь', 'пряничник', 'практикант', 'тузлук', 'плач', 'вареник', 'рислинг', 'транш', 'укупорщик', 'усложнение', 'фальшивомонетничество', 'пышность', 'подстановка', 'санитар', 'линовальщик', 'септик', 'пережидание', 'фалл', 'наивность', 'метафизичность', 'вычищение', 'лярд', 'передрессировывание', 'долгожитель', 'метрополитен', 'прошивка', 'подчитывание', 'ёлка', 'подкрутка', 'аил', 'концепция', 'обмол', 'обиженная', 'жертвенник', 'отчизна', 'шёпот', 'обмыливание', 'водохранилище', 'пантовар', 'притачка', 'кардиография', 'навинчивание', 'угнетённость', 'высокопарность', 'ломаная', 'непоследовательность', 'дилетант', 'разгром', 'горло', 'коалиция', 'федералист', 'отдыхающий', 'неудовлетворительность', 'театральность', 'шурфование', 'подгрузка', 'привкус', 'крольчатина', 'ярка', 'декабристка', 'неоклассик', 'откус', 'педфак', 'одежда', 'евпатория', 'индонезия', 'кастрюля', 'качели', 'мамонт', 'копье', 'колледж', 'авиаметеостанция', 'гороскоп', 'марево', 'десница', 'мозоль', 'копоть', 'креветка', 'качалка', 'конвейер', 'алоэ', 'камбуз', 'катализатор', 'ладонь', 'крыло', 'кий', 'амфибия', 'бородавка', 'кафтан', 'стул', 'иордания', 'электричка', 'пещера', 'мундир', 'водоросль', 'бар', 'балерина', 'граната', 'брус', 'купальня', 'башмачок', 'берлин', 'жеребец', 'воробей', 'сова', 'леденец', 'арена', 'узел', 'софа', 'утюг', 'ландыш', 'вакцина', 'бурьян', 'погреб', 'душ', 'гамбург', 'джунгли', 'голень', 'желток', 'лохмотья', 'берег', 'голгофа', 'шкатулка', 'венок', 'малыш', 'кемпинг', 'паркет', 'баня', 'департамент', 'боекомплект', 'канзас', 'дренаж', 'капсула', 'автомагистраль', 'антиквар', 'мотор', 'карамелька', 'лев', 'впадина', 'декада', 'масленка', 'медпункт', 'мультфильм', 'лотерея', 'калория', 'говядина', 'камфара', 'зубок', 'лимузин', 'бильярд', 'колдобина', 'иероглиф', 'воск', 'шпаргалка', 'траншея', 'авиастроитель', 'пряник', 'бром', 'автопоезд', 'кортик', 'дыхание', 'империя', 'плов']\n",
        "len(_global_words_0), len(_global_words_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wht9zSZa5dw_",
        "outputId": "43442606-1e0e-4b7d-ea00-222916119418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "class WordsDataset(data.Dataset):\n",
        "    def __init__(self, batch_size=8):\n",
        "        super().__init__()\n",
        "        self.batch_size = batch_size\n",
        "        # Формирование порядковых номеров символов\n",
        "        _text = \"\".join(_global_words_0 + _global_words_1).lower()\n",
        "        self.alphabet = set(_text) # набор символов\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet))) # число в символ\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()} # символ в число\n",
        "        self.alphabet_size = len(self.alphabet)\n",
        "\n",
        "        # Формируем data и target для объединённого списка\n",
        "        words = [[w, 0] for w in _global_words_0] + [[w, 1] for w in _global_words_1]\n",
        "        self.data = sorted(words, key=lambda item: (len(item[0])))\n",
        "        self.length = (len(self.data) + batch_size - 1) // batch_size\n",
        "\n",
        "    # формирование и возвращение батча данных по индексу item\n",
        "    def __getitem__(self, item):\n",
        "        batch = self.data[self.batch_size * item:self.batch_size * (item + 1)]\n",
        "        max_len = max(len(x[0]) for x in batch)\n",
        "\n",
        "        for i in range(len(batch)):\n",
        "            # Кодирование слов цифрами и паддинг минус единицей\n",
        "            batch[i][0] = [self.alpha_to_int.get(c, 0) for c in batch[i][0]]\n",
        "            batch[i][0] += [-1] * (max_len - len(batch[i][0]))\n",
        "\n",
        "        # One-hot по словарю плюс -1 → 0\n",
        "        batch_indices = torch.tensor([x[0] for x in batch])  # (batch_size, seq_len)\n",
        "\n",
        "        # Создаём eye неквадратную, чтобы посл. строка кодировала -1 → 0:\n",
        "        eye = torch.eye(self.alphabet_size + 1, self.alphabet_size)\n",
        "        data = eye[batch_indices] # (batch_size, seq_length, size_one_hot): [8, 3, 34]\n",
        "        # size_one_hot больше размера словаря на единицу\n",
        "        # Поскольку добавляется вариант с нулевой строкой\n",
        "\n",
        "        target = torch.tensor([x[1] for x in batch]).unsqueeze(-1).float() # (batch_size, 1)\n",
        "\n",
        "        return data, target\n",
        "\n",
        "\n",
        "    def __len__(self): # возврат размер обучающей выборки в батчах\n",
        "        return self.length\n",
        "\n",
        "d_train = WordsDataset(batch_size=8)\n",
        "train_data = data.DataLoader(d_train, batch_size=1, shuffle=True)\n",
        "\n",
        "# '''\n",
        "a = WordsDataset()\n",
        "print(len(a))\n",
        "print(a[0][0].shape, a[0][1].shape) # (batch_size, seq_length, size_one_hot), (batch_size, 1)\n",
        "print(a[50][0])\n",
        "# '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEay9ugF6BYP",
        "outputId": "82744605-61ac-4dcc-c9a2-dfe730bb2689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75\n",
            "torch.Size([8, 3, 34])\n",
            "torch.Size([8, 3, 34])\n",
            "torch.Size([8, 3, 34]) torch.Size([8, 1])\n",
            "torch.Size([8, 7, 34])\n",
            "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 1., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         ...,\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "class WordsDataset(data.Dataset):\n",
        "    def __init__(self, batch_size=8): # инициализатор класса\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.words_lst = [(_x, 0) for _x in _global_words_0] + [(_x, 1) for _x in _global_words_1]\n",
        "        self.words_lst.sort(key=lambda _x: len(_x[0]))\n",
        "        self.dataset_len = len(self.words_lst)\n",
        "\n",
        "        _text = \"\".join(_global_words_0 + _global_words_1).lower()\n",
        "        self.alphabet = set(_text)\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet)))\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()}\n",
        "        self.num_characters = len(self.alphabet)\n",
        "        self.onehots = torch.eye(self.num_characters + 1, self.num_characters)\n",
        "\n",
        "    def __getitem__(self, item): # формирование и возвращение батча данных по индексу item\n",
        "        item *= self.batch_size\n",
        "        item_last = item + self.batch_size\n",
        "        if item_last > self.dataset_len:\n",
        "            item_last = self.dataset_len\n",
        "\n",
        "        max_length = len(self.words_lst[item_last - 1][0])\n",
        "\n",
        "        d = [[self.alpha_to_int[_x] for _x in _w[0]] + [-1] * (max_length - len(_w[0])) for _w in self.words_lst[item: item_last]]\n",
        "        t = torch.FloatTensor([_w[1] for _w in self.words_lst[item: item_last]])\n",
        "\n",
        "        data = torch.zeros(len(d), max_length, self.num_characters)\n",
        "        for i, indx in enumerate(d):\n",
        "            data[i, :, :] = self.onehots[indx]\n",
        "\n",
        "        return data, t\n",
        "\n",
        "    def __len__(self): # возврат размер обучающей выборки в батчах\n",
        "        last = 0 if self.dataset_len % self.batch_size == 0 else 1\n",
        "        return self.dataset_len // self.batch_size + last\n",
        "\n",
        "\n",
        "# здесь продолжайте программу\n",
        "d_train = WordsDataset(batch_size=8)\n",
        "train_data = data.DataLoader(d_train, batch_size=1, shuffle=True)\n",
        "\n",
        "# '''\n",
        "a = WordsDataset()\n",
        "print(len(a))\n",
        "print(a[0][0].shape, a[0][1].shape) # (batch_size, seq_length, size_one_hot), (batch_size, 1)\n",
        "print(a[50][0])\n",
        "# '''"
      ],
      "metadata": {
        "id": "tfMYnTbgqdFJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}