{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8uqdmQr+OZRxKb3NvqNfx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576179/step/10"
      ],
      "metadata": {
        "id": "jvM0JMYFrFgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as tfs\n",
        "\n",
        "class ToDtypeV1:\n",
        "    def __init__(self, dtype=torch.float32, scale=False):\n",
        "        self.dtype = dtype\n",
        "        self.scale = scale\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = img.to(self.dtype)  # преобразование в заданный формат\n",
        "\n",
        "        # # Масштабирование с \"контрастностью\"\n",
        "        if self.scale and self.dtype in (torch.float16, torch.float32, torch.float64):\n",
        "            img = (img - img.min()) / img.max()\n",
        "\n",
        "        # Масштабирование с простым переносом из диапазона [0, 1] в диапазоне [0, 255]\n",
        "        # if self.scale and self.dtype in (torch.float16, torch.float32, torch.float64):\n",
        "        #     img = img / 255.0\n",
        "\n",
        "        return img\n",
        "\n",
        "# Исходное изображение\n",
        "H, W = 128, 128\n",
        "img_orig = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8) # тензор в программе не менять\n",
        "\n",
        "# Расчет средних и отклонений\n",
        "img_mean = img_orig.float().mean(dim=(1, 2))  # средние для каждого цветового канала (первая ось)\n",
        "img_std = img_orig.float().std(dim=1, unbiased=False).mean(dim=1)    # отклонение для каждого цветового канала (первая ось)\n",
        "\n",
        "# Функция для группы преобразований\n",
        "to_tensor = tfs.Compose([ToDtypeV1(dtype=torch.float32, scale=False),\n",
        "                         tfs.Normalize(mean=img_mean, std=img_std)])\n",
        "\n",
        "# Применение группы преобразований\n",
        "img = to_tensor(img_orig)\n",
        "\n",
        "# # Проверка\n",
        "# print(\"Форма преобразованного изображения:\")\n",
        "# print(img.shape)\n",
        "# print(\"Средние (первая ось):\")\n",
        "# print(img_mean)\n",
        "# print(\"Отклонения (первая ось):\")\n",
        "# print(img_std)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8kzjEfoy3Vv",
        "outputId": "3359a689-93ce-42cc-d1f3-2d72cca1bf39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Форма преобразованного изображения:\n",
            "torch.Size([3, 128, 128])\n",
            "Средние (первая ось):\n",
            "tensor([127.5753, 127.1597, 128.2852])\n",
            "Отклонения (первая ось):\n",
            "tensor([73.0897, 73.1175, 73.6554])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as tfs\n",
        "# import torchvision.transforms.v2 as tfs_v2 - недоступен на Stepik\n",
        "\n",
        "class ToDtypeV1(nn.Module):\n",
        "    def __init__(self, dtype, scale=False):\n",
        "        super().__init__()\n",
        "        self.dtype = dtype\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, item):\n",
        "        item = item.to(self.dtype)\n",
        "        if self.scale and self.dtype in (torch.float16, torch.float32, torch.float64):\n",
        "            item_min = item.min()\n",
        "            item_max = item.max()\n",
        "            item = (item - item_min) / item_max\n",
        "\n",
        "        return item\n",
        "\n",
        "\n",
        "H, W = 128, 128\n",
        "img_orig = torch.randint(0, 256, size=(3, H, W), dtype=torch.uint8) # тензор в программе не менять\n",
        "\n",
        "img_mean = torch.mean(img_orig.float(), [1, 2])\n",
        "img_std = torch.std(img_orig.float().flatten(1, 2), dim=1)\n",
        "transforms = tfs.Compose([ToDtypeV1(dtype=torch.float32, scale=False),\n",
        "                          tfs.Normalize(mean=img_mean, std=img_std)\n",
        "                          ])\n",
        "\n",
        "img = transforms(img_orig)\n",
        "\n",
        "# # Проверка\n",
        "print(\"Преобразованное изображение:\")\n",
        "print(img_transform.shape)\n",
        "print(\"Средние (первая ось):\")\n",
        "print(img_mean)\n",
        "print(\"Отклонения (первая ось):\")\n",
        "print(img_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1k0F99dcI0J",
        "outputId": "dcf240a1-20d1-4718-abcc-18286c58d349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Преобразованное изображение:\n",
            "torch.Size([3, 128, 128])\n",
            "Средние (первая ось):\n",
            "tensor([127.3781, 126.5436, 127.8182])\n",
            "Отклонения (первая ось):\n",
            "tensor([73.7543, 73.9360, 74.1318])\n"
          ]
        }
      ]
    }
  ]
}
