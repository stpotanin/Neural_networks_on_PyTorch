{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlcCtSSmHnR8FTCThY6RL2"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576195/step/6"
      ],
      "metadata": {
        "id": "RPHkpMt_ob1J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VerjQ7oToaQh",
        "outputId": "59bab2d6-4399-477d-93c6-6c76daccb8b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import torchvision.transforms.functional as TF\n",
        "# import torchvision.transforms.v2 as tfs_v2\n",
        "\n",
        "# тензор x и img_pil в программе не менять\n",
        "x = torch.randint(0, 255, (3, 250, 250), dtype=torch.float32)\n",
        "img_pil = TF.to_pil_image(x)\n",
        "\n",
        "# transforms = tfs_v2.Compose([tfs_v2.ToImage(), tfs_v2.ToDtype(torch.float32, scale=True)])\n",
        "transforms = models.ResNet50_Weights.DEFAULT.transforms()\n",
        "inp_img = transforms(img_pil)\n",
        "\n",
        "model = models.resnet50()\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(512*4, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n",
        "model.requires_grad_(False)\n",
        "model.eval()\n",
        "\n",
        "predict = model(inp_img.unsqueeze(0))\n",
        "# print(predict.shape)"
      ]
    }
  ]
}