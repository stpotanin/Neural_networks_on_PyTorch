{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPnozdNV/Ciieu6IRuoXf5R"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576195/step/8"
      ],
      "metadata": {
        "id": "5CVGlMns2qI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqKg39882lxb",
        "outputId": "7f6e992d-f589-414a-fd24-26278c175182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[58000.0390625, 3705.9929131401914, 430.9513530731201, 85.20848337809245, 34.44961049821642, 23.521960682339138, 19.50560885005528, 18.379872534010147, 18.04986233181424, 17.378559960259334, 17.50553406609429, 17.526691648695202, 17.30922285715739, 17.085827933417427, 16.803658379448787, 17.058402379353844, 16.40661409166124, 15.860542880164251, 16.22151358922323, 15.998286777072483]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class FuncModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # модель однослойной полносвязной нейронной сети:\n",
        "        # 1-й слой: число входов 5 (x, x^2, x^3, x^4, x^5), число нейронов 1\n",
        "        self.layer = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x.unsqueeze_(-1)\n",
        "        xx = torch.cat([x, x ** 2, x ** 3, x ** 4, x ** 5], dim=1)\n",
        "        y = self.layer(xx)\n",
        "        return y\n",
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "model = FuncModel()\n",
        "\n",
        "epochs = 20 # число эпох обучения\n",
        "batch_size = 16 # размер батча\n",
        "\n",
        "# данные обучающей выборки (значения функции)\n",
        "data_x = torch.arange(-5, 5, 0.05) #тензоры data_x, data_y не менять\n",
        "data_y = torch.sin(2 * data_x) - 0.3 * torch.cos(8 * data_x) + 0.1 * data_x ** 2\n",
        "\n",
        "ds = data.TensorDataset(data_x, data_y) # создание dataset\n",
        "d_train, d_val = data.random_split(ds, [0.7, 0.3])\n",
        "train_data = data.DataLoader(d_train, batch_size=batch_size, shuffle=True)\n",
        "train_data_val = data.DataLoader(d_val, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "optimizer = optim.RMSprop(params=model.parameters(), lr=0.01)\n",
        "loss_func = nn.MSELoss()\n",
        "\n",
        "loss_lst_val = []   # список значений потерь при валидации\n",
        "loss_lst = []       # список значений потерь при обучении\n",
        "\n",
        "for _e in range(epochs):\n",
        "    model.train()\n",
        "    loss_mean = 0 # вспомогательные переменные для вычисления среднего значения потерь при обучении\n",
        "    lm_count = 0\n",
        "\n",
        "    for x_train, y_train in train_data:\n",
        "        predict = model(x_train).squeeze()\n",
        "        loss = loss_func(predict, y_train)\n",
        "\n",
        "        optimizer.zero_grad()       # очистка градиента\n",
        "        loss.backward()             # обратное распространение ошибки\n",
        "        optimizer.step()            # обновление параметров сети\n",
        "        # loss_mean += loss.item()    # накопление потерь по батчам\n",
        "        # lm_count += 1\n",
        "\n",
        "        # вычисление среднего значения функции потерь по всей выборке\n",
        "        lm_count += 1\n",
        "        loss_mean = 1 / lm_count * loss.item() + (1 - 1 / lm_count) * loss_mean\n",
        "\n",
        "    # валидация модели\n",
        "    model.eval()\n",
        "    Q_val = 0\n",
        "    count_val = 0\n",
        "\n",
        "    for x_val, y_val in train_data_val:\n",
        "        with torch.no_grad():\n",
        "            predict = model(x_val).squeeze()\n",
        "            loss = loss_func(predict, y_val)\n",
        "            Q_val += loss.item()\n",
        "            count_val += 1\n",
        "\n",
        "    # сохранить средние потери, вычисленные по выборке валидации, в переменной Q_val\n",
        "    Q_val /= count_val\n",
        "\n",
        "    loss_lst.append(loss_mean)\n",
        "    loss_lst_val.append(Q_val)\n",
        "\n",
        "model.eval()\n",
        "# выполнить прогноз модели по всем данным выборки (ds.data)\n",
        "preds = model(data_x)\n",
        "# вычислить потери с помощью loss_func по всем данным выборки ds; значение Q сохранить в виде вещественного числа\n",
        "Q = loss_func(preds.flatten(), data_y).item()\n",
        "\n",
        "# print(Q)\n",
        "# print(loss_lst)"
      ]
    }
  ]
}
