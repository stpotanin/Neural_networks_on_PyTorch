{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6Bk+i8itbo6b1+nwlVUOU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576200/step/7\n",
        "\n",
        "https://github.com/selfedu-rus/neuro-pytorch/blob/main/solves/4.3.5"
      ],
      "metadata": {
        "id": "Qa02x_yx2kor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrc2D4ED2eX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd82930-6ce2-4624-ce0a-6bffed6835db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "нейронная сеть                     \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# сюда копируйте класс CharsDataset из предыдущего подвига\n",
        "class CharsDataset(data.Dataset):\n",
        "    def __init__(self, prev_chars=10):\n",
        "        super().__init__()\n",
        "        self.prev_chars = prev_chars\n",
        "        self.rows = _global_var_text\n",
        "        all_text = \"\".join(self.rows).lower()\n",
        "\n",
        "        self.alphabet = set(all_text.lower()) # сэт из символов текста\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet))) # отсортированный cловарь\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()} # обратный словарь\n",
        "\n",
        "        # Генерация данных\n",
        "        self.data = []\n",
        "        for row in self.rows:\n",
        "            row = row.lower()\n",
        "            for i in range(len(row) - prev_chars):\n",
        "                self.data.append(([self.alpha_to_int[c] for c in row[i:i+prev_chars]],\n",
        "                                  self.alpha_to_int[row[i+prev_chars]]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.data[idx]\n",
        "        # one-hot-конвертация:\n",
        "        x_onehot = torch.zeros(self.prev_chars, len(self.alphabet))\n",
        "        x_onehot[torch.arange(self.prev_chars), torch.tensor(x)] = 1\n",
        "\n",
        "        return x_onehot, torch.tensor(y)\n",
        "\n",
        "# здесь объявляйте класс модели нейронной сети\n",
        "class RNN_Model(nn.Module):\n",
        "    def __init__(self, in_features, out_linear):\n",
        "        super().__init__()\n",
        "        self.rnn = nn.RNN(in_features, 32, batch_first=True)\n",
        "        self.linear = nn.Linear(32, out_linear, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, h = self.rnn(x)\n",
        "        return self.linear(h)\n",
        "\n",
        "# # Переменная для теста\n",
        "# _global_var_text = [\n",
        "# \"Как я отмечал во введении, простейшая НС – персептрон, представляет собой\",\n",
        "# \"Это классический пример полносвязной сети\",\n",
        "# \"Каждая связь между нейронами имеет определенный\"\n",
        "# ]\n",
        "\n",
        "# сюда копируйте объекты d_train и train_data\n",
        "d_train = CharsDataset(prev_chars=10)\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "\n",
        "n = len(d_train.alphabet) # число входов и выходовв сети (размер словаря)\n",
        "\n",
        "model = RNN_Model(n, n)\n",
        "\n",
        "# Оптимизатор и функция потерь\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 1 # число эпох (это конечно, очень мало, в реальности нужно от 100 и более)\n",
        "model.train() # переводим модель в режим обучения\n",
        "\n",
        "# Цикл обучепния\n",
        "for _e in range(epochs):\n",
        "    for x_train, y_train in train_data:\n",
        "        predict = model(x_train).squeeze(0)\n",
        "        loss = loss_func(predict, y_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval() # переводим модель в режим предсказания\n",
        "predict = \"нейронная сеть \".lower() # начальная фраза\n",
        "total = 20 # число прогнозируемых символов (дополнительно к начальной фразе)\n",
        "\n",
        "# выполните прогноз следующих total символов\n",
        "\n",
        "# Цикл прогноза\n",
        "for _ in range(total):\n",
        "    # Подготовка для one-hot-конвертации:\n",
        "    x_input = torch.zeros(1, 10, n)\n",
        "\n",
        "    # Делаем срез последних 10-ти символов\n",
        "    for i, key in enumerate(predict[-10:]):\n",
        "        # Окончание one-hot-конвертации\n",
        "        # Помечаем единицей индекс, соответствующий символу (по ключу в словаре)\n",
        "        x_input[0, i, d_train.alpha_to_int[key]] = 1\n",
        "\n",
        "    # Прогноз модели по сформированному срезу\n",
        "    output = model(x_input)\n",
        "\n",
        "    # Выбираем символ с максимальной вероятностью (его ключ/индекс)\n",
        "    key = torch.argmax(output).item()\n",
        "\n",
        "    # По индексу выбираем из словаря предсказанный символ и приклеиваем к строке\n",
        "    predict += d_train.int_to_alpha[key]\n",
        "\n",
        "# выведите полученную строку на экран\n",
        "print(predict)\n",
        "len(predict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title тестовое решение для проверки системы\n",
        "# https://github.com/selfedu-rus/neuro-pytorch/blob/main/solves/4.3.5\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "class CharsDataset(data.Dataset):\n",
        "    def __init__(self, prev_chars=7):\n",
        "        self.prev_chars = prev_chars\n",
        "\n",
        "        self.lines = _global_var_text\n",
        "        self.alphabet = set((\"\".join(self.lines)).lower())\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet)))\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()}\n",
        "        self.num_characters = len(self.alphabet)\n",
        "        self.onehots = torch.eye(self.num_characters)\n",
        "\n",
        "        data = []\n",
        "        targets = []\n",
        "\n",
        "        for i, t in enumerate(self.lines):\n",
        "            t = t.lower()\n",
        "            for item in range(len(t)-self.prev_chars):\n",
        "                data.append([self.alpha_to_int[t[x]] for x in range(item, item + self.prev_chars)])\n",
        "                targets.append(self.alpha_to_int[t[item+self.prev_chars]])\n",
        "\n",
        "        self.data = torch.tensor(data)\n",
        "        self.targets = torch.tensor(targets)\n",
        "\n",
        "        self.length = len(data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.onehots[self.data[item]], self.targets[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "class TextRNN(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super().__init__()\n",
        "        self.hidden_size = 32\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "\n",
        "        self.rnn = nn.RNN(in_features, self.hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_size, out_features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, h = self.rnn(x)\n",
        "        y = self.out(h)\n",
        "        return y\n",
        "\n",
        "\n",
        "# сюда копируйте объекты d_train и train_data\n",
        "d_train = CharsDataset(prev_chars=10)\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "\n",
        "model = TextRNN(d_train.num_characters, d_train.num_characters)\n",
        "\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.01)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "epochs = 1 # число эпох\n",
        "model.train()\n",
        "\n",
        "for _e in range(epochs):\n",
        "    for x_train, y_train in train_data:\n",
        "        predict = model(x_train).squeeze(0)\n",
        "        loss = loss_func(predict, y_train.long())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "predict = \"нейронная сеть \".lower() # начальная фраза\n",
        "total = 20 # число прогнозируемых символов (дополнительно к начальной фразе)\n",
        "\n",
        "for _ in range(total):\n",
        "    _data = d_train.onehots[[d_train.alpha_to_int[predict[-x]] for x in range(d_train.prev_chars, 0, -1)]]\n",
        "    with torch.no_grad():\n",
        "        p = model(_data.unsqueeze(0)).squeeze(0)\n",
        "    indx = torch.argmax(p, dim=1)\n",
        "    predict += d_train.int_to_alpha[indx.item()]\n",
        "\n",
        "print(predict)\n",
        "len(predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oILGldzyqOdx",
        "outputId": "6f92ad00-c18a-4e67-cbbf-3a1c76f84ace"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "нейронная сеть ееееееееееееееееееее\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}
