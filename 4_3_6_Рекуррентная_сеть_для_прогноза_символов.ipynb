{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB/oj2PQrvXgQoPM9Pyy+z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1576200/step/6\n",
        "\n",
        "https://github.com/selfedu-rus/neuro-pytorch/blob/main/solves/4.3.4"
      ],
      "metadata": {
        "id": "Qa02x_yx2kor"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrc2D4ED2eX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeee2835-b8ed-46a0-83a5-14947a5f6d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 10, 28]) torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "class CharsDataset(data.Dataset):\n",
        "    def __init__(self, prev_chars=10):\n",
        "        super().__init__()\n",
        "        self.prev_chars = prev_chars\n",
        "        self.rows = _global_var_text\n",
        "        all_text = \"\".join(self.rows).lower()\n",
        "\n",
        "        self.alphabet = set(all_text.lower()) # сэт из символов текста\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet))) # отсортированный cловарь\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()} # обратный словарь\n",
        "\n",
        "        # Генерация данных\n",
        "        # Вариант склеить все строки в одну, а затем обрабатывать (не по заданию)\n",
        "        # Размер получится больше, так как выдадим больше прогнозов\n",
        "        self.ds = [\n",
        "            ([self.alpha_to_int[c] for c in all_text[i:i+prev_chars]],\n",
        "             self.alpha_to_int[all_text[i+prev_chars]])\n",
        "             for i in range(len(all_text) - prev_chars)\n",
        "        ]\n",
        "\n",
        "        # Вариант обработки построчно (по заданию)\n",
        "        self.data = []\n",
        "        for row in self.rows:\n",
        "            row = row.lower()\n",
        "            for i in range(len(row) - prev_chars):\n",
        "                self.data.append(([self.alpha_to_int[c] for c in row[i:i+prev_chars]],\n",
        "                                  self.alpha_to_int[row[i+prev_chars]]))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, y = self.data[idx]\n",
        "        # one-hot-конвертация:\n",
        "        x_onehot = torch.zeros(self.prev_chars, len(self.alphabet))\n",
        "        x_onehot[torch.arange(self.prev_chars), torch.tensor(x)] = 1\n",
        "\n",
        "        return x_onehot, torch.tensor(y)\n",
        "\n",
        "# Переменная для теста\n",
        "_global_var_text = [\n",
        "\"Как я отмечал во введении, простейшая НС – персептрон, представляет собой\",\n",
        "\"Это классический пример полносвязной сети\",\n",
        "\"Каждая связь между нейронами имеет определенный\"\n",
        "]\n",
        "\n",
        "d_train = CharsDataset(prev_chars=10)\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "\n",
        "# Проверка\n",
        "for x, y in train_data:\n",
        "    print(x.shape, y.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "\n",
        "\n",
        "# здесь объявляйте класс CharsDataset\n",
        "class CharsDataset(data.Dataset):\n",
        "    def __init__(self, prev_chars=7):\n",
        "        self.prev_chars = prev_chars\n",
        "\n",
        "        self.lines = _global_var_text\n",
        "        self.alphabet = set((\"\".join(self.lines)).lower())\n",
        "        self.int_to_alpha = dict(enumerate(sorted(self.alphabet)))\n",
        "        self.alpha_to_int = {b: a for a, b in self.int_to_alpha.items()}\n",
        "        self.num_characters = len(self.alphabet)\n",
        "        self.onehots = torch.eye(self.num_characters)\n",
        "\n",
        "        data = []\n",
        "        targets = []\n",
        "\n",
        "        for i, t in enumerate(self.lines):\n",
        "            t = t.lower()\n",
        "            for item in range(len(t)-self.prev_chars):\n",
        "                data.append([self.alpha_to_int[t[x]] for x in range(item, item + self.prev_chars)])\n",
        "                targets.append(self.alpha_to_int[t[item+self.prev_chars]])\n",
        "\n",
        "        self.data = torch.tensor(data)\n",
        "        self.targets = torch.tensor(targets)\n",
        "\n",
        "        self.length = len(data)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.onehots[self.data[item]], self.targets[item]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "\n",
        "# здесь продолжайте программу\n",
        "d_train = CharsDataset(prev_chars=10)\n",
        "train_data = data.DataLoader(d_train, batch_size=8, shuffle=True)\n",
        "\n",
        "a = CharsDataset()\n",
        "\n",
        "print(len(a))\n",
        "a[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QW_yZPC92Y4",
        "outputId": "eb8aecbd-8d88-4c09-96a7-ad4925c72bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
              " tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ]
}